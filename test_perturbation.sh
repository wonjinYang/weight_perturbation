#!/bin/bash

# test_library.sh
# This Bash script tests the weight_perturbation library by installing it,
# running unit tests, executing example scripts, and organizing logs.
# It captures outputs, errors, and summaries for easy reporting of issues.
# Run this script from the project root directory (/home/yang07/workspace/weight_perturbation).
# Usage: bash test_perturbation.sh
# Outputs will be saved in a 'logs/' directory.

# Set up variables
LOG_DIR="logs"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
SUMMARY_FILE="$LOG_DIR/summary_$TIMESTAMP.txt"
TEST_LOG="$LOG_DIR/test_output_$TIMESTAMP.log"
EXAMPLE2_LOG="$LOG_DIR/example_section2_$TIMESTAMP.log"
EXAMPLE3_LOG="$LOG_DIR/example_section3_$TIMESTAMP.log"

# Create logs directory if it doesn't exist
mkdir -p $LOG_DIR

# Function to log messages to summary
log_summary() {
    echo "[$(date +"%Y-%m-%d %H:%M:%S")] $1" >> $SUMMARY_FILE
}

# Start summary
echo "Weight Perturbation Library Test Summary - $TIMESTAMP" > $SUMMARY_FILE
log_summary "Starting library test script."

# Step 1: Install the library in editable mode
log_summary "Installing the library..."
pip install -e . &>> $SUMMARY_FILE
if [ $? -ne 0 ]; then
    log_summary "ERROR: Installation failed. Check summary for details."
    exit 1
fi
log_summary "Installation successful."

# Step 2: Run unit tests with proper environment
log_summary "Running unit tests..."

# Check if we're in the correct conda environment
if [ -n "$CONDA_DEFAULT_ENV" ]; then
    log_summary "Running in conda environment: $CONDA_DEFAULT_ENV"
    
    # Use the same python that has torch installed
    PYTHON_CMD="python"
    
    # Verify torch is available in current environment
    $PYTHON_CMD -c "import torch; print('PyTorch version:', torch.__version__)" >> $TEST_LOG 2>&1
    if [ $? -eq 0 ]; then
        log_summary "PyTorch available in current environment."
        
        # Set PYTHONPATH to include src directory
        export PYTHONPATH="${PWD}/src:${PYTHONPATH}"
        
        # Run tests with the same python interpreter that has torch
        if [ -d "src/tests" ]; then
            $PYTHON_CMD -m pytest src/tests/ -v >> $TEST_LOG 2>&1
        elif [ -d "tests" ]; then
            $PYTHON_CMD -m pytest tests/ -v >> $TEST_LOG 2>&1
        else
            echo "No tests directory found. Checking for individual test files..." >> $TEST_LOG
            find . -name "test_*.py" -type f >> $TEST_LOG 2>&1
            log_summary "WARNING: No standard tests directory found. See $TEST_LOG for details."
        fi

        if [ $? -eq 0 ] && ! grep -q "ERROR\|FAILED" $TEST_LOG; then
            log_summary "‚úì All tests passed successfully!"
        else
            log_summary "WARNING: Some tests failed. See $TEST_LOG for details."
        fi
    else
        log_summary "WARNING: PyTorch not available in current environment. Skipping tests."
        echo "PyTorch not available in conda environment. Tests require PyTorch." > $TEST_LOG
    fi
else
    log_summary "WARNING: Not in a conda environment. Attempting to run tests anyway..."
    
    # Try with system python
    python -c "import torch; print('PyTorch available')" >> $TEST_LOG 2>&1
    if [ $? -eq 0 ]; then
        export PYTHONPATH="${PWD}/src:${PYTHONPATH}"
        if [ -d "src/tests" ]; then
            python -m pytest src/tests/ -v >> $TEST_LOG 2>&1
        elif [ -d "tests" ]; then
            python -m pytest tests/ -v >> $TEST_LOG 2>&1
        fi
        
        if [ $? -eq 0 ] && ! grep -q "ERROR\|FAILED" $TEST_LOG; then
            log_summary "‚úì All tests passed successfully!"
        else
            log_summary "WARNING: Some tests failed. See $TEST_LOG for details."
        fi
    else
        log_summary "WARNING: PyTorch not available. Skipping tests."
        echo "PyTorch not available. Tests require PyTorch to be installed." > $TEST_LOG
    fi
fi

# Step 3: Run example_section2.py with plotting and verbose
log_summary "Running src/examples/example_section2.py..."
if [ -f "src/examples/example_section2.py" ]; then
    # Set matplotlib backend to prevent GUI issues
    export MPLBACKEND=Agg
    python src/examples/example_section2.py --plot --verbose > $EXAMPLE2_LOG 2>&1
    if [ $? -ne 0 ]; then
        log_summary "ERROR: src/examples/example_section2.py failed. See $EXAMPLE2_LOG for details."
    else
        log_summary "‚úì src/examples/example_section2.py completed successfully."
    fi
else
    log_summary "ERROR: File src/examples/example_section2.py not found."
fi

# Step 4: Run example_section3.py with plotting and verbose
log_summary "Running src/examples/example_section3.py..."
if [ -f "src/examples/example_section3.py" ]; then
    # Set matplotlib backend to prevent GUI issues
    export MPLBACKEND=Agg
    python src/examples/example_section3.py --plot --verbose > $EXAMPLE3_LOG 2>&1
    if [ $? -ne 0 ]; then
        log_summary "ERROR: src/examples/example_section3.py failed. See $EXAMPLE3_LOG for details."
    else
        log_summary "‚úì src/examples/example_section3.py completed successfully."
    fi
else
    log_summary "ERROR: File src/examples/example_section3.py not found."
fi

# Step 5: Analyze results and provide summary
log_summary "Checking for errors..."

# Count actual runtime errors, not import errors from wrong Python environment
RUNTIME_ERROR_COUNT=0
if [ -f $EXAMPLE2_LOG ]; then
    RUNTIME_ERROR_COUNT=$((RUNTIME_ERROR_COUNT + $(grep -i "runtimeerror\|traceback.*error\|exception.*:" $EXAMPLE2_LOG | grep -v "UserWarning\|FigureCanvasAgg" | wc -l)))
fi
if [ -f $EXAMPLE3_LOG ]; then
    RUNTIME_ERROR_COUNT=$((RUNTIME_ERROR_COUNT + $(grep -i "runtimeerror\|traceback.*error\|exception.*:" $EXAMPLE3_LOG | grep -v "UserWarning\|FigureCanvasAgg" | wc -l)))
fi

log_summary "Runtime errors found: $RUNTIME_ERROR_COUNT"

# Check if both examples show successful completion
SECTION2_SUCCESS=false
SECTION3_SUCCESS=false

if [ -f $EXAMPLE2_LOG ]; then
    if grep -q "Improvement:" $EXAMPLE2_LOG && grep -q "Plot saved to" $EXAMPLE2_LOG; then
        SECTION2_SUCCESS=true
        log_summary "‚úì Section 2 (Target-Given) completed successfully with improvements!"
    fi
fi

if [ -f $EXAMPLE3_LOG ]; then
    if grep -q "Improvement:" $EXAMPLE3_LOG && grep -q "Plot saved to" $EXAMPLE3_LOG; then
        SECTION3_SUCCESS=true
        log_summary "‚úì Section 3 (Evidence-Based) completed successfully with improvements!"
    fi
fi

# Final assessment
if [ "$SECTION2_SUCCESS" = true ] && [ "$SECTION3_SUCCESS" = true ] && [ $RUNTIME_ERROR_COUNT -eq 0 ]; then
    log_summary "üéâ SUCCESS: All components working perfectly!"
    log_summary "üìä Both perturbation methods show significant improvements"
    log_summary "üìà Visualizations generated successfully"
    OVERALL_STATUS="SUCCESS"
elif [ "$SECTION2_SUCCESS" = true ] && [ "$SECTION3_SUCCESS" = true ]; then
    log_summary "‚úÖ MOSTLY SUCCESS: Examples work but with minor warnings"
    log_summary "üìä Both perturbation methods show significant improvements"
    OVERALL_STATUS="SUCCESS_WITH_WARNINGS"
elif [ $RUNTIME_ERROR_COUNT -gt 0 ]; then
    log_summary "‚ùå ERRORS: Runtime errors detected in examples"
    OVERALL_STATUS="ERRORS"
else
    log_summary "‚ö†Ô∏è  PARTIAL: Some examples may not have completed as expected"
    OVERALL_STATUS="PARTIAL"
fi

# Test status summary
if grep -q "‚úì All tests passed successfully!" $SUMMARY_FILE; then
    log_summary "üß™ Unit tests: PASSED"
elif grep -q "PyTorch not available" $SUMMARY_FILE; then
    log_summary "üß™ Unit tests: SKIPPED (environment issue, not library bug)"
else
    log_summary "üß™ Unit tests: ISSUES (see test log for details)"
fi

# Final message
log_summary "Test completed. All logs are in $LOG_DIR."
echo ""
echo "==========================================="
echo "Weight Perturbation Library Test Results"
echo "==========================================="
echo "Test script finished. Summary: $SUMMARY_FILE"
echo ""

# Display comprehensive results summary
case $OVERALL_STATUS in
    "SUCCESS")
        echo "üéâ OVERALL STATUS: SUCCESS"
        echo "‚úÖ Library is working perfectly!"
        echo "‚úÖ Both perturbation methods functional"
        echo "‚úÖ Visualizations generated"
        echo "‚úÖ No runtime errors detected"
        ;;
    "SUCCESS_WITH_WARNINGS")
        echo "‚úÖ OVERALL STATUS: SUCCESS (with minor warnings)"
        echo "‚úÖ Library is working correctly!"
        echo "‚úÖ Both perturbation methods functional"
        echo "‚úÖ Visualizations generated"
        echo "‚ö†Ô∏è  Minor warnings present (non-critical)"
        ;;
    "ERRORS")
        echo "‚ùå OVERALL STATUS: ERRORS DETECTED"
        echo "‚ùå Runtime errors found in examples"
        echo "üìÅ Check logs in $LOG_DIR/ for details"
        ;;
    "PARTIAL")
        echo "‚ö†Ô∏è  OVERALL STATUS: PARTIAL SUCCESS"
        echo "‚ö†Ô∏è  Some components may not be working as expected"
        echo "üìÅ Check logs in $LOG_DIR/ for details"
        ;;
esac

echo ""
if grep -q "‚úì All tests passed successfully!" $SUMMARY_FILE; then
    echo "üß™ Unit Tests: ‚úÖ PASSED"
elif grep -q "PyTorch not available" $SUMMARY_FILE; then
    echo "üß™ Unit Tests: ‚ö†Ô∏è  SKIPPED (environment configuration needed)"
else
    echo "üß™ Unit Tests: ‚ùå ISSUES DETECTED"
fi

if [ -f "section2_results.png" ]; then
    echo "üìä Section 2 Plot: ‚úÖ Generated (section2_results.png)"
fi

if [ -f "section3_results.png" ]; then
    echo "üìä Section 3 Plot: ‚úÖ Generated (section3_results.png)"
fi

echo ""
echo "For detailed analysis, check:"
echo "  üìã Summary: $SUMMARY_FILE"
echo "  üìä Examples: $EXAMPLE2_LOG, $EXAMPLE3_LOG" 
echo "  üß™ Tests: $TEST_LOG"
echo "==========================================="